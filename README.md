2019/7/2
√1.去除重复值的方法 set,unique
√2.多任务，进程，并行，线程，并发
  华为张志峰：
  多任务意味着多进程，一个任务可能对应着多个进程，但一个任务至少有一个线程。多线程是处理并发的一种编程范式，多进程实际是一种并行（编辑word的时候听歌）。
  华为姚凯强：
  多任务就是多进程，一个任务就需要一个进程来处理，不确定一个任务是否用多进程处理。并发和多线程不是一回事，并发是一种系统状态，是业务决定的（抢红包）；而   多线程是一种处理任务的方法，多线程可以使得系统承受更高的并发状态。进程是并行的。
√3.行列式的几何意义
  二阶行列式的几何意义是向量张成的平行四边形的有向面积，三阶行列式的几何意义是向量张成的平行六面体的有向体积，以此类推。
√4.python伪多线程
  python多线程是单CPU意义上的多线程，与多CPU多线程有本质区别。
  多CPU多线程=并行（真正的同一时刻CPU独立承担任务）内部包含并发（时间片轮转）。
  单CPU多线程=并发（时间片轮转）。
  原因：全局解释器锁（GIL）使得同一时刻只能有一个线程对python对象进行操作，多线程变为了类似时间片轮转的操作。
 5.特征空间
√6.PCA投影（projection）方差最大，信息越多
  PCA本质上是在保持尽量多特征的前提下，将高维特征映射到低维特征。
  X（N,M）=Y（N,D）×W（D,M）其中N个样本没变，但每个样本中的特征维度从D降到M，本质上就是求变换矩阵W，或一个M维度的特征向量
  通过一系列推导，本质上方差越大，特征值越大，特征向量的“特征”越明显。
  
√7.jupyter的文件是在本地还是服务器
  本地，通过ipynb文件可以编辑。
8.奇异值分解的物理含义
  先了解特征值分解和奇异值分解的理论。
  总的来说，奇异值分解是将一个复杂的矩阵分解成若干子矩阵的相乘，子矩阵表征原矩阵的重要特征。
2019/7/3
√1.函数凹凸性对于优化问题的影响
一般将非凸函数转化为凸函数进行求解，因为在数学上证明了，如果一个问题可以转化为凸函数，那么这个问题就比较好解决。
如果更严格地，求解问题可转化为凸优化问题，那么局部最优解一定是全局最优解。
√2.loss函数的选定
  loss函数有非常多，需要根据具体的应用选定，对模型预测效果影响很大。
√3.学习速率的选择
  先大（精度丢失，震荡）后小（过拟合，收敛慢）
√4.过拟合
  拟合能力强，从而预测能力弱（泛化能力弱），lr动态调整，动量项，dropout等
√5.局部最优解

